{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dd9922f-c3ab-4136-8d4c-3e83b1eac462",
   "metadata": {},
   "source": [
    "# NVP para ajustar datos originales y latentes\n",
    "\n",
    "Se implementa una red neuronal conocida como flujo normalizador que ajustara en los datos originales y latentes una distribucion de probabilidad para modelar la complejidad de ambos espacios de alta dimensión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33b6642a-89e9-45d0-bfd2-59d30207dadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d847578-b346-4509-a560-9f1a6e46bbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1007_s_at</th>\n",
       "      <th>1053_at</th>\n",
       "      <th>117_at</th>\n",
       "      <th>121_at</th>\n",
       "      <th>1255_g_at</th>\n",
       "      <th>1294_at</th>\n",
       "      <th>1316_at</th>\n",
       "      <th>1320_at</th>\n",
       "      <th>1405_i_at</th>\n",
       "      <th>1431_at</th>\n",
       "      <th>...</th>\n",
       "      <th>AFFX-r2-Ec-bioD-3_at</th>\n",
       "      <th>AFFX-r2-Ec-bioD-5_at</th>\n",
       "      <th>AFFX-r2-P1-cre-3_at</th>\n",
       "      <th>AFFX-r2-P1-cre-5_at</th>\n",
       "      <th>AFFX-ThrX-3_at</th>\n",
       "      <th>AFFX-ThrX-5_at</th>\n",
       "      <th>AFFX-ThrX-M_at</th>\n",
       "      <th>AFFX-TrpnX-3_at</th>\n",
       "      <th>AFFX-TrpnX-5_at</th>\n",
       "      <th>AFFX-TrpnX-M_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.801198</td>\n",
       "      <td>4.553189</td>\n",
       "      <td>6.787790</td>\n",
       "      <td>5.430893</td>\n",
       "      <td>3.250222</td>\n",
       "      <td>6.272688</td>\n",
       "      <td>3.413405</td>\n",
       "      <td>3.374910</td>\n",
       "      <td>3.654116</td>\n",
       "      <td>3.804983</td>\n",
       "      <td>...</td>\n",
       "      <td>10.735084</td>\n",
       "      <td>10.398843</td>\n",
       "      <td>12.298551</td>\n",
       "      <td>12.270505</td>\n",
       "      <td>3.855588</td>\n",
       "      <td>3.148321</td>\n",
       "      <td>3.366087</td>\n",
       "      <td>3.199008</td>\n",
       "      <td>3.160388</td>\n",
       "      <td>3.366417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.585956</td>\n",
       "      <td>4.193540</td>\n",
       "      <td>3.763183</td>\n",
       "      <td>6.003593</td>\n",
       "      <td>3.309387</td>\n",
       "      <td>6.291927</td>\n",
       "      <td>3.754777</td>\n",
       "      <td>3.587603</td>\n",
       "      <td>5.137159</td>\n",
       "      <td>8.622475</td>\n",
       "      <td>...</td>\n",
       "      <td>11.528447</td>\n",
       "      <td>11.369919</td>\n",
       "      <td>12.867048</td>\n",
       "      <td>12.560433</td>\n",
       "      <td>4.016561</td>\n",
       "      <td>3.282867</td>\n",
       "      <td>3.541994</td>\n",
       "      <td>3.548680</td>\n",
       "      <td>3.460083</td>\n",
       "      <td>3.423348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.803370</td>\n",
       "      <td>4.134075</td>\n",
       "      <td>3.433113</td>\n",
       "      <td>5.395057</td>\n",
       "      <td>3.476944</td>\n",
       "      <td>5.825713</td>\n",
       "      <td>3.505036</td>\n",
       "      <td>3.687333</td>\n",
       "      <td>4.515175</td>\n",
       "      <td>12.681439</td>\n",
       "      <td>...</td>\n",
       "      <td>10.892460</td>\n",
       "      <td>10.416151</td>\n",
       "      <td>12.356337</td>\n",
       "      <td>11.888482</td>\n",
       "      <td>3.839367</td>\n",
       "      <td>3.598851</td>\n",
       "      <td>3.516791</td>\n",
       "      <td>3.484089</td>\n",
       "      <td>3.282626</td>\n",
       "      <td>3.512024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.920840</td>\n",
       "      <td>4.000651</td>\n",
       "      <td>3.754500</td>\n",
       "      <td>5.645297</td>\n",
       "      <td>3.387530</td>\n",
       "      <td>6.470458</td>\n",
       "      <td>3.629249</td>\n",
       "      <td>3.577534</td>\n",
       "      <td>5.192624</td>\n",
       "      <td>11.759412</td>\n",
       "      <td>...</td>\n",
       "      <td>10.686871</td>\n",
       "      <td>10.524836</td>\n",
       "      <td>12.006596</td>\n",
       "      <td>11.846195</td>\n",
       "      <td>3.867602</td>\n",
       "      <td>3.180472</td>\n",
       "      <td>3.309547</td>\n",
       "      <td>3.425501</td>\n",
       "      <td>3.166613</td>\n",
       "      <td>3.377499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.556480</td>\n",
       "      <td>4.599010</td>\n",
       "      <td>4.066155</td>\n",
       "      <td>6.344537</td>\n",
       "      <td>3.372081</td>\n",
       "      <td>5.439280</td>\n",
       "      <td>3.762213</td>\n",
       "      <td>3.440714</td>\n",
       "      <td>4.961625</td>\n",
       "      <td>10.318552</td>\n",
       "      <td>...</td>\n",
       "      <td>11.014454</td>\n",
       "      <td>10.775566</td>\n",
       "      <td>12.657182</td>\n",
       "      <td>12.573076</td>\n",
       "      <td>4.091440</td>\n",
       "      <td>3.306729</td>\n",
       "      <td>3.493704</td>\n",
       "      <td>3.205771</td>\n",
       "      <td>3.378567</td>\n",
       "      <td>3.392938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22277 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1007_s_at   1053_at    117_at    121_at  1255_g_at   1294_at   1316_at  \\\n",
       "0   6.801198  4.553189  6.787790  5.430893   3.250222  6.272688  3.413405   \n",
       "1   7.585956  4.193540  3.763183  6.003593   3.309387  6.291927  3.754777   \n",
       "2   7.803370  4.134075  3.433113  5.395057   3.476944  5.825713  3.505036   \n",
       "3   6.920840  4.000651  3.754500  5.645297   3.387530  6.470458  3.629249   \n",
       "4   6.556480  4.599010  4.066155  6.344537   3.372081  5.439280  3.762213   \n",
       "\n",
       "    1320_at  1405_i_at    1431_at  ...  AFFX-r2-Ec-bioD-3_at  \\\n",
       "0  3.374910   3.654116   3.804983  ...             10.735084   \n",
       "1  3.587603   5.137159   8.622475  ...             11.528447   \n",
       "2  3.687333   4.515175  12.681439  ...             10.892460   \n",
       "3  3.577534   5.192624  11.759412  ...             10.686871   \n",
       "4  3.440714   4.961625  10.318552  ...             11.014454   \n",
       "\n",
       "   AFFX-r2-Ec-bioD-5_at  AFFX-r2-P1-cre-3_at  AFFX-r2-P1-cre-5_at  \\\n",
       "0             10.398843            12.298551            12.270505   \n",
       "1             11.369919            12.867048            12.560433   \n",
       "2             10.416151            12.356337            11.888482   \n",
       "3             10.524836            12.006596            11.846195   \n",
       "4             10.775566            12.657182            12.573076   \n",
       "\n",
       "   AFFX-ThrX-3_at  AFFX-ThrX-5_at  AFFX-ThrX-M_at  AFFX-TrpnX-3_at  \\\n",
       "0        3.855588        3.148321        3.366087         3.199008   \n",
       "1        4.016561        3.282867        3.541994         3.548680   \n",
       "2        3.839367        3.598851        3.516791         3.484089   \n",
       "3        3.867602        3.180472        3.309547         3.425501   \n",
       "4        4.091440        3.306729        3.493704         3.205771   \n",
       "\n",
       "   AFFX-TrpnX-5_at  AFFX-TrpnX-M_at  \n",
       "0         3.160388         3.366417  \n",
       "1         3.460083         3.423348  \n",
       "2         3.282626         3.512024  \n",
       "3         3.166613         3.377499  \n",
       "4         3.378567         3.392938  \n",
       "\n",
       "[5 rows x 22277 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocesamiento de datos\n",
    "data = pd.read_csv('Liver_GSE14520_U133A.csv')\n",
    "data.drop(['samples','type'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e3b27c7-0b05-4663-a8e6-199c529e68ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización de los datos\n",
    "data = data.values.astype(np.float32)\n",
    "data = StandardScaler().fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e5140fa-6a61-4e15-a273-26a2a4227539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definimos una funcion que tomara un numero aleatorio de caracteristicas por experimento\n",
    "def get_random_subset(data, n_features, seed=None):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    n_cols = data.shape[1]\n",
    "    index = np.random.choice(n_cols, size=n_features, replace=False)\n",
    "    return data[:, index], index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f7264bb-0575-49ce-8c39-6ff3c5d93034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas seleccionadas: [ 1385 19688  4501  4158  2051 20456 17802  3294 19909   415]\n"
     ]
    }
   ],
   "source": [
    "subset1, index1 = get_random_subset(data, n_features=1000, seed=1)\n",
    "print(\"Columnas seleccionadas:\", index1[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ce795570-7c69-46ca-ac59-d8fd6ee80c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas seleccionadas: [20590  5641 18293  2163 13520 21277 15527 19294  9461 15239]\n"
     ]
    }
   ],
   "source": [
    "subset2, index2 = get_random_subset(data, n_features=2000, seed=2)\n",
    "print(\"Columnas seleccionadas:\", index2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e5b7339a-b050-4337-8455-8e70a860bf39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▃▃▅▄▂▄▅▅█▂▃▃▃▅▄▂▃▄▃▃▅▃▂▂▄▅▁▅▁▂▃▂▃▄▃▂▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>1440.27625</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">misunderstood-feather-8</strong> at: <a href='https://wandb.ai/libni-reyesma-fcfm-buap/Experimentos%20para%20NVP/runs/k1kf2188' target=\"_blank\">https://wandb.ai/libni-reyesma-fcfm-buap/Experimentos%20para%20NVP/runs/k1kf2188</a><br> View project at: <a href='https://wandb.ai/libni-reyesma-fcfm-buap/Experimentos%20para%20NVP' target=\"_blank\">https://wandb.ai/libni-reyesma-fcfm-buap/Experimentos%20para%20NVP</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251202_045342-k1kf2188/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20251202_045423-fnzeiwe2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/libni-reyesma-fcfm-buap/Experimentos%20para%20NVP/runs/fnzeiwe2' target=\"_blank\">whole-snow-9</a></strong> to <a href='https://wandb.ai/libni-reyesma-fcfm-buap/Experimentos%20para%20NVP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/libni-reyesma-fcfm-buap/Experimentos%20para%20NVP' target=\"_blank\">https://wandb.ai/libni-reyesma-fcfm-buap/Experimentos%20para%20NVP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/libni-reyesma-fcfm-buap/Experimentos%20para%20NVP/runs/fnzeiwe2' target=\"_blank\">https://wandb.ai/libni-reyesma-fcfm-buap/Experimentos%20para%20NVP/runs/fnzeiwe2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "run = wandb.init(project = \"Experimentos para NVP\",\n",
    "                 config ={ #configuramos los hiperparametros\n",
    "                     \"learning_rate\": 1e-6, \n",
    "                     \"epochs\": 50,\n",
    "                     \"num_blocks\": num_blocks,\n",
    "                     \"hidden_units\": hidden_units,\n",
    "                     \"input_dim\":input_dim,\n",
    "                     \"optimizer\": \"Adam\",\n",
    "                     \"n_features\": 1000\n",
    "                 })\n",
    "config = wandb.config\n",
    "            \n",
    "                     \n",
    "                    \n",
    "\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "67166def-5b3d-4a03-af54-989cfda56a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generamos un dataset de tensorflow\n",
    "dataset = tf.data.Dataset.from_tensor_slices(subset1)\n",
    "dataset = dataset.shuffle(buffer_size=357).batch(57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "72a58196-241d-46f7-8e57-6bf14be73e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "num_blocks = 2\n",
    "hidden_units = 50\n",
    "input_dim = subset1.shape\n",
    "\n",
    "class RealNVP(keras.Model):\n",
    "    def __init__(self, input_dim, num_blocks, hidden_units, base_distribution=None, **kwargs):\n",
    "        super(RealNVP, self).__init__(**kwargs)\n",
    "        self.input_dim = input_dim                                                \n",
    "        self.num_blocks = num_blocks\n",
    "        self.hidden_units = hidden_units\n",
    "        self.base_distribution = base_distribution or tfd.MultivariateNormalDiag(  #distribucion normal diagonal de media cero y varianza uno\n",
    "            loc=tf.zeros(input_dim),\n",
    "            scale_diag=tf.ones(input_dim)\n",
    "        )\n",
    "        self.nll_tracker = keras.metrics.Mean(name=\"nll\")\n",
    "        # Flujo de z->x cadena de bijectors\n",
    "        bijectors = []\n",
    "        self.nets = []\n",
    "        \n",
    "\n",
    "        for i in range(num_blocks):\n",
    "            net =  tfb.real_nvp_default_template(        #usamos la plantilla de red densa pequeña \n",
    "                [hidden_units, hidden_units],\n",
    "                name=f\"NN_{i}\"\n",
    "            )\n",
    "            self.nets.append(net)\n",
    "            bijectors.append(\n",
    "                tfb.RealNVP(  \n",
    "                    shift_and_log_scale_fn=net, \n",
    "                    num_masked=input_dim // 2,           #enmascara la mitad de las 20000 características\n",
    "                    name=f\"RealNVP_{i}\"\n",
    "                )\n",
    "            )\n",
    "            bijectors.append(                            \n",
    "                tfb.Permute(\n",
    "                    permutation=tf.random.shuffle(tf.range(input_dim)),  #se añade una permutación para asegurar que todas las dimensiones interactuen \n",
    "                    name=f\"Permute_{i}\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.flow_bijector = tfb.Chain(list(reversed(bijectors)))\n",
    "        self.flow_distribution = tfd.TransformedDistribution(            #creamos la distribucion transformada\n",
    "            distribution=self.base_distribution,\n",
    "            bijector=self.flow_bijector\n",
    "        )\n",
    "        self.trainable_vars = []                                       #los bijectors con el atributo shift_and_log_scale tienen los\n",
    "        for b in self.flow_distribution.bijector.bijectors:            #parámetros de traslación y escala para las dimensiones transformadas\n",
    "            if hasattr(b, \"shift_and_log_scale_fn\") and hasattr(b.shift_and_log_scale_fn, \"trainable_variables\"):\n",
    "                self.trainable_vars += b.shift_and_log_scale_fn.trainable_variables\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "            return self.flow_distribution(inputs)  \n",
    "   \n",
    "    @property\n",
    "    def metrics(self):\n",
    "            return [self.nll_tracker]\n",
    "\n",
    "    def train_step(self, data):\n",
    "            with tf.GradientTape() as tape:\n",
    "                nll = -tf.reduce_mean(self.flow_distribution.log_prob(data)) #verosimilitud de que los datos originales sean observados bajo la distro \n",
    "            grads = tape.gradient(nll, self.trainable_vars)\n",
    "            self.optimizer.apply_gradients(zip(grads, self.trainable_vars))\n",
    "            self.nll_tracker.update_state(nll)\n",
    "            return {\"loss\": nll}\n",
    "        # Loguear métricas en W&B\n",
    "            wandb.log({\n",
    "                \"nll\": nll.numpy(),\n",
    "                \"grad_norm\": grad_norm.numpy()\n",
    "            })\n",
    "\n",
    "        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3f15fb9a-caf7-4da5-b302-a4507876d037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_train_batch_end` time: 0.0040s). Check your callbacks.\n",
      "7/7 [==============================] - 1s 5ms/step - loss: 1521.3538\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1538.6700\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1531.7133\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1488.4084\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1523.0266\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1557.3339\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1521.1020\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1490.7388\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1534.4680\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1501.3297\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1481.5375\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1500.5729\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1502.2095\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1506.5624\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1488.2493\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1596.7006\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1580.9252\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1501.4899\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1472.6145\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1559.6000\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1479.0685\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1530.7122\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1573.9724\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1502.7602\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1533.5007\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1521.0062\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1511.6493\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1552.4835\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1532.3764\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1505.9708\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1490.6932\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1523.3532\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1493.1539\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1507.7935\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1549.8358\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1495.0948\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1529.5918\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1536.9726\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1513.8300\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1498.7943\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1512.5478\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1515.7769\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 1499.4821\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1525.4658\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1504.9450\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1491.7120\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1545.5363\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1496.7250\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1545.4664\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1498.5040\n"
     ]
    }
   ],
   "source": [
    "normalizing_flow = RealNVP(config.n_features, config.num_blocks, config.hidden_units)\n",
    "normalizing_flow.compile(optimizer=keras.optimizers.Adam(config.learning_rate))\n",
    "history = normalizing_flow.fit(dataset,epochs=config.epochs,callbacks=[wandb.keras.WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a506d53-fc0e-4a5b-81ea-0cf7afa7c866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
