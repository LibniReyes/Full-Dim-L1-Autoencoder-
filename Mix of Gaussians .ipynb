{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0687402-6e00-434d-a6af-2cc3305d17cd",
   "metadata": {},
   "source": [
    "# Modelo de mezcla de gaussianas para aproximar el espacio original y latente \n",
    "Se implementa un modelo probabilistico en tensorflow probability para aproximar una distribucion de probabilidad a los dato originales y los de el espacio latente usando una mezcla de Gaussianas.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "217c1aa2-2321-46c0-ac1e-146c90eae5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 18:12:00.828166: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-09 18:12:00.903800: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-09 18:12:00.943783: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8473] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-12-09 18:12:00.961036: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1471] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-09 18:12:01.020034: I tensorflow/core/platform/cpu_feature_guard.cc:211] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f56da676-0847-4bcb-bbe7-93cfb8469940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1007_s_at</th>\n",
       "      <th>1053_at</th>\n",
       "      <th>117_at</th>\n",
       "      <th>121_at</th>\n",
       "      <th>1255_g_at</th>\n",
       "      <th>1294_at</th>\n",
       "      <th>1316_at</th>\n",
       "      <th>1320_at</th>\n",
       "      <th>1405_i_at</th>\n",
       "      <th>1431_at</th>\n",
       "      <th>...</th>\n",
       "      <th>AFFX-r2-Ec-bioD-3_at</th>\n",
       "      <th>AFFX-r2-Ec-bioD-5_at</th>\n",
       "      <th>AFFX-r2-P1-cre-3_at</th>\n",
       "      <th>AFFX-r2-P1-cre-5_at</th>\n",
       "      <th>AFFX-ThrX-3_at</th>\n",
       "      <th>AFFX-ThrX-5_at</th>\n",
       "      <th>AFFX-ThrX-M_at</th>\n",
       "      <th>AFFX-TrpnX-3_at</th>\n",
       "      <th>AFFX-TrpnX-5_at</th>\n",
       "      <th>AFFX-TrpnX-M_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.801198</td>\n",
       "      <td>4.553189</td>\n",
       "      <td>6.787790</td>\n",
       "      <td>5.430893</td>\n",
       "      <td>3.250222</td>\n",
       "      <td>6.272688</td>\n",
       "      <td>3.413405</td>\n",
       "      <td>3.374910</td>\n",
       "      <td>3.654116</td>\n",
       "      <td>3.804983</td>\n",
       "      <td>...</td>\n",
       "      <td>10.735084</td>\n",
       "      <td>10.398843</td>\n",
       "      <td>12.298551</td>\n",
       "      <td>12.270505</td>\n",
       "      <td>3.855588</td>\n",
       "      <td>3.148321</td>\n",
       "      <td>3.366087</td>\n",
       "      <td>3.199008</td>\n",
       "      <td>3.160388</td>\n",
       "      <td>3.366417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.585956</td>\n",
       "      <td>4.193540</td>\n",
       "      <td>3.763183</td>\n",
       "      <td>6.003593</td>\n",
       "      <td>3.309387</td>\n",
       "      <td>6.291927</td>\n",
       "      <td>3.754777</td>\n",
       "      <td>3.587603</td>\n",
       "      <td>5.137159</td>\n",
       "      <td>8.622475</td>\n",
       "      <td>...</td>\n",
       "      <td>11.528447</td>\n",
       "      <td>11.369919</td>\n",
       "      <td>12.867048</td>\n",
       "      <td>12.560433</td>\n",
       "      <td>4.016561</td>\n",
       "      <td>3.282867</td>\n",
       "      <td>3.541994</td>\n",
       "      <td>3.548680</td>\n",
       "      <td>3.460083</td>\n",
       "      <td>3.423348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.803370</td>\n",
       "      <td>4.134075</td>\n",
       "      <td>3.433113</td>\n",
       "      <td>5.395057</td>\n",
       "      <td>3.476944</td>\n",
       "      <td>5.825713</td>\n",
       "      <td>3.505036</td>\n",
       "      <td>3.687333</td>\n",
       "      <td>4.515175</td>\n",
       "      <td>12.681439</td>\n",
       "      <td>...</td>\n",
       "      <td>10.892460</td>\n",
       "      <td>10.416151</td>\n",
       "      <td>12.356337</td>\n",
       "      <td>11.888482</td>\n",
       "      <td>3.839367</td>\n",
       "      <td>3.598851</td>\n",
       "      <td>3.516791</td>\n",
       "      <td>3.484089</td>\n",
       "      <td>3.282626</td>\n",
       "      <td>3.512024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.920840</td>\n",
       "      <td>4.000651</td>\n",
       "      <td>3.754500</td>\n",
       "      <td>5.645297</td>\n",
       "      <td>3.387530</td>\n",
       "      <td>6.470458</td>\n",
       "      <td>3.629249</td>\n",
       "      <td>3.577534</td>\n",
       "      <td>5.192624</td>\n",
       "      <td>11.759412</td>\n",
       "      <td>...</td>\n",
       "      <td>10.686871</td>\n",
       "      <td>10.524836</td>\n",
       "      <td>12.006596</td>\n",
       "      <td>11.846195</td>\n",
       "      <td>3.867602</td>\n",
       "      <td>3.180472</td>\n",
       "      <td>3.309547</td>\n",
       "      <td>3.425501</td>\n",
       "      <td>3.166613</td>\n",
       "      <td>3.377499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.556480</td>\n",
       "      <td>4.599010</td>\n",
       "      <td>4.066155</td>\n",
       "      <td>6.344537</td>\n",
       "      <td>3.372081</td>\n",
       "      <td>5.439280</td>\n",
       "      <td>3.762213</td>\n",
       "      <td>3.440714</td>\n",
       "      <td>4.961625</td>\n",
       "      <td>10.318552</td>\n",
       "      <td>...</td>\n",
       "      <td>11.014454</td>\n",
       "      <td>10.775566</td>\n",
       "      <td>12.657182</td>\n",
       "      <td>12.573076</td>\n",
       "      <td>4.091440</td>\n",
       "      <td>3.306729</td>\n",
       "      <td>3.493704</td>\n",
       "      <td>3.205771</td>\n",
       "      <td>3.378567</td>\n",
       "      <td>3.392938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22277 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1007_s_at   1053_at    117_at    121_at  1255_g_at   1294_at   1316_at  \\\n",
       "0   6.801198  4.553189  6.787790  5.430893   3.250222  6.272688  3.413405   \n",
       "1   7.585956  4.193540  3.763183  6.003593   3.309387  6.291927  3.754777   \n",
       "2   7.803370  4.134075  3.433113  5.395057   3.476944  5.825713  3.505036   \n",
       "3   6.920840  4.000651  3.754500  5.645297   3.387530  6.470458  3.629249   \n",
       "4   6.556480  4.599010  4.066155  6.344537   3.372081  5.439280  3.762213   \n",
       "\n",
       "    1320_at  1405_i_at    1431_at  ...  AFFX-r2-Ec-bioD-3_at  \\\n",
       "0  3.374910   3.654116   3.804983  ...             10.735084   \n",
       "1  3.587603   5.137159   8.622475  ...             11.528447   \n",
       "2  3.687333   4.515175  12.681439  ...             10.892460   \n",
       "3  3.577534   5.192624  11.759412  ...             10.686871   \n",
       "4  3.440714   4.961625  10.318552  ...             11.014454   \n",
       "\n",
       "   AFFX-r2-Ec-bioD-5_at  AFFX-r2-P1-cre-3_at  AFFX-r2-P1-cre-5_at  \\\n",
       "0             10.398843            12.298551            12.270505   \n",
       "1             11.369919            12.867048            12.560433   \n",
       "2             10.416151            12.356337            11.888482   \n",
       "3             10.524836            12.006596            11.846195   \n",
       "4             10.775566            12.657182            12.573076   \n",
       "\n",
       "   AFFX-ThrX-3_at  AFFX-ThrX-5_at  AFFX-ThrX-M_at  AFFX-TrpnX-3_at  \\\n",
       "0        3.855588        3.148321        3.366087         3.199008   \n",
       "1        4.016561        3.282867        3.541994         3.548680   \n",
       "2        3.839367        3.598851        3.516791         3.484089   \n",
       "3        3.867602        3.180472        3.309547         3.425501   \n",
       "4        4.091440        3.306729        3.493704         3.205771   \n",
       "\n",
       "   AFFX-TrpnX-5_at  AFFX-TrpnX-M_at  \n",
       "0         3.160388         3.366417  \n",
       "1         3.460083         3.423348  \n",
       "2         3.282626         3.512024  \n",
       "3         3.166613         3.377499  \n",
       "4         3.378567         3.392938  \n",
       "\n",
       "[5 rows x 22277 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocesamiento de datos\n",
    "data = pd.read_csv('Liver_GSE14520_U133A.csv')\n",
    "data.drop(['samples','type'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f4da05f-3820-4f45-b4f6-0e9951322893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización de los datos\n",
    "data = data.values.astype(np.float32)\n",
    "data = StandardScaler().fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a28359c2-0eae-487b-a665-fba7a9b79c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765303931.301558    2915 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1765303931.611344    2915 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1765303931.611383    2915 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1765303931.616925    2915 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1765303931.616977    2915 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1765303931.616989    2915 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1765303931.992340    2915 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1765303931.992390    2915 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-09 18:12:11.992423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1765303931.992477    2915 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-09 18:12:11.992557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2878 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 5050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 12.0\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(data).batch(51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebe3650f-d48e-4676-9731-76c4b332f070",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5e4b53e-ee1c-438a-81b0-ecf9ddf6ed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd = tfp.distributions\n",
    "\n",
    "locs = tf.Variable(tf.random.normal([3, input_dim])) # inicializamos las medias en valores aleatorios de una distribucion normal\n",
    "scales = tf.Variable(tf.ones([3, input_dim]))        # inicializamos el ancho de las distribuciones en 1\n",
    "logits = tf.Variable(tf.zeros([3]))                  # inicializamos los pesos de la mezcla en 0\n",
    "\n",
    "def MixOfGaussians():\n",
    "    return tfd.MixtureSameFamily(\n",
    "        mixture_distribution=tfd.Categorical(logits=logits),\n",
    "        components_distribution=tfd.MultivariateNormalDiag( \n",
    "            loc=locs,\n",
    "            scale_diag=tf.nn.softplus(scales) #aseguramos desviación estandar >0\n",
    "        )\n",
    "    )\n",
    "\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.05)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        MoG = MixOfGaussians()\n",
    "        loss = -tf.reduce_mean(MoG.log_prob(batch))\n",
    "    gradients = tape.gradient(loss, [locs, scales, logits])\n",
    "    optimizer.apply_gradients(zip(gradients, [locs, scales, logits]))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8014e52-6ff8-4dd3-875f-9c6d06e85c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765303933.444186    2995 service.cc:146] XLA service 0x714bfaabfb80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1765303933.444246    2995 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 5050 Laptop GPU, Compute Capability 12.0\n",
      "2025-12-09 18:12:13.452693: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-12-09 18:12:13.532509: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90701\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "I0000 00:00:1765303933.596122    2995 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "'+ptx85' is not a recognized feature for this target (ignoring feature)\n",
      "2025-12-09 18:12:13.698712: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-12-09 18:12:13.723650: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-12-09 18:12:13.774640: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 34724.3594\n",
      "Epoch 1, Loss: 32025.0215\n",
      "Epoch 2, Loss: 30198.1758\n",
      "Epoch 3, Loss: 29000.5117\n",
      "Epoch 4, Loss: 28215.2207\n",
      "Epoch 5, Loss: 27611.5293\n",
      "Epoch 6, Loss: 27075.0586\n",
      "Epoch 7, Loss: 26575.5078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 18:12:13.878427: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 26070.8535\n",
      "Epoch 9, Loss: 25612.2969\n",
      "Epoch 10, Loss: 25246.4453\n",
      "Epoch 11, Loss: 24969.8086\n",
      "Epoch 12, Loss: 24709.9121\n",
      "Epoch 13, Loss: 24502.4297\n",
      "Epoch 14, Loss: 24392.2617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-09 18:12:14.131961: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 24340.6328\n",
      "Epoch 16, Loss: 24322.7559\n",
      "Epoch 17, Loss: 24319.7598\n",
      "Epoch 18, Loss: 24323.6855\n",
      "Epoch 19, Loss: 24326.8477\n",
      "Epoch 20, Loss: 24329.8574\n",
      "Epoch 21, Loss: 24326.8105\n",
      "Epoch 22, Loss: 24325.5176\n",
      "Epoch 23, Loss: 24322.6074\n",
      "Epoch 24, Loss: 24319.3086\n",
      "Epoch 25, Loss: 24318.8770\n",
      "Epoch 26, Loss: 24316.9336\n",
      "Epoch 27, Loss: 24316.3809\n",
      "Epoch 28, Loss: 24315.7148\n",
      "Epoch 29, Loss: 24315.1367\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):  \n",
    "    for batch in dataset:\n",
    "        loss = train_step(batch)\n",
    "    print(f\"Epoch {epoch}, Loss: {loss.numpy():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61e7dca-4e1a-422f-b4db-a2531a056b52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
